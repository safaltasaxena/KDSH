# Narrative Consistency via Constraint Reasoning

This repository contains our submission for the **Kharagpur Data Science Hackathon (KDSH 2026)**.
The project tackles the problem of **global narrative consistency**: determining whether a *hypothetical backstory* of a character is logically and causally consistent with the *entire long-form narrative* (100k+ words) of a novel.

Unlike surface-level LLM reasoning, our approach explicitly **extracts, tracks, embeds, and evaluates long-term narrative constraints** and reduces the task to a principled **constraint consistency decision problem**.

---

## ğŸš€ Motivation

Large Language Models excel at local plausibility but often fail at **global consistency** across long narratives. They:

* Miss long-range contradictions
* Confuse similarity with causality
* Fail to accumulate evidence over time

This system replaces plausibility-based reasoning with **constraint-based reasoning**, ensuring that any proposed backstory respects the irreversible events, stable beliefs, traits, capabilities, and relationships established throughout the story.

---

## ğŸ§  Core Idea

Given:

1. A complete novel (no truncation)
2. A newly written, plausible hypothetical backstory

We ask:

> *Could this backstory logically and causally produce the observed narrative?*

The system outputs a **binary decision**:

* `1` â†’ Backstory is globally consistent
* `0` â†’ Backstory is globally inconsistent

---

## ğŸ§© Constraint Taxonomy

We model five types of long-term, non-reversible constraints:

1. **Belief Constraints**
   Stable worldviews inferred from repeated actions (e.g., distrusts authority).

2. **Trait Constraints**
   Persistent personality characteristics (e.g., loyal, impulsive).

3. **Capability Constraints**
   Skills or abilities that enable or prevent actions (e.g., can fight, cannot read).

4. **Irreversible Event Constraints**
   Permanent events that cannot be undone (e.g., death, betrayal).

5. **Relationship Constraints**
   Stable interpersonal relationships (e.g., loyal to X, hostile to Y).

### Constraint Severity

* **Hard Constraints** â†’ Immediate failure (score = 0)
* **Soft Constraints** â†’ Aggregated and thresholded

---

## ğŸ—ï¸ System Architecture

```
Books (.txt)
   â†“
Chunking & Cleaning
   â†“
Constraint Extraction (LLM)
   â†“
Constraint Embedding (Vector Store)
   â†“
Backstory Claim Extraction
   â†“
Claimâ€“Constraint Retrieval (Cosine Similarity)
   â†“
Contradiction Scoring
   â†“
Score Aggregation
   â†“
Binary Decision (0 / 1)
```

---

## ğŸ“ Repository Structure

```
narrative-consistency/
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ constraints.md            # Constraint taxonomy & theory
â”‚   â”œâ”€â”€ problem_reformulation.md  # Formal task definition
â”‚   â””â”€â”€ why_llms_fail.md          # Motivation & failure modes
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ingest_books.py           # Book ingestion & chunking
â”‚   â”œâ”€â”€ extract_constraints.py    # Constraint extraction pipeline
â”‚   â”œâ”€â”€ embed_constraints.py      # Embedding constraints using OpenAI
â”‚   â”œâ”€â”€ extract_claims.py         # Backstory claim extraction
â”‚   â”œâ”€â”€ check_stats.py            # Dataset statistics
â”‚   â””â”€â”€ diagnose_flatness.py      # Score distribution diagnostics
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ constraint_extractor.py   # Core constraint extraction logic
â”‚   â”œâ”€â”€ claim_extractor.py        # Claim extraction logic
â”‚   â”œâ”€â”€ contradiction_logic.py    # Soft/Hard contradiction scoring
â”‚   â””â”€â”€ decision.py               # Score aggregation & labeling
â”‚
â”œâ”€â”€ main.py                       # End-to-end consistency check
â”œâ”€â”€ main_eval.py                  # Training evaluation & threshold tuning
â”œâ”€â”€ main_day3.py                  # Pathway-based pipeline
â”œâ”€â”€ requirements.txt
â””â”€â”€ Problem_Statement.md
```

---

## âš™ï¸ Installation

```bash
git clone https://github.com/<your-username>/narrative-consistency.git
cd narrative-consistency
pip install -r requirements.txt
```

Set your OpenAI API key:

```bash
export OPENAI_API_KEY="your_api_key"
```

---

## â–¶ï¸ Running the Pipeline

### 1ï¸âƒ£ Ingest and Chunk Books

```bash
python scripts/ingest_books.py
```

### 2ï¸âƒ£ Extract Narrative Constraints

```bash
python scripts/extract_constraints.py
```

### 3ï¸âƒ£ Embed Constraints

```bash
python scripts/embed_constraints.py
```

### 4ï¸âƒ£ Extract Backstory Claims

```bash
python scripts/extract_claims.py
```

### 5ï¸âƒ£ Evaluate Consistency

```bash
python main_eval.py
```

Or run a single backstory check:

```bash
python main.py
```

---

## ğŸ“Š Evaluation

* Retrieval via cosine similarity over embedded constraints
* Contradiction scoring via symbolic + LLM-assisted logic
* Aggregation via weighted accumulation
* Final decision via tunable threshold

Baseline comparison against majority label included.

---

## ğŸ§ª Track Alignment

* **Track A (Systems Reasoning with NLP & GenAI)** âœ…
* Uses Pathway for ingestion & orchestration
* Hybrid symbolic + neural reasoning
* Explicit long-context constraint tracking

---

## ğŸš« Explicit Exclusions

To ensure robustness and interpretability, we do **not** model:

* Emotional states
* Literary symbolism
* Unreliable narration
* One-off actions
* Psychological speculation

---

## ğŸ Key Takeaway

> Narrative consistency is not about plausibility â€” it is about **respecting constraints over time**.

This system demonstrates how long-form reasoning can be reduced to a structured, testable decision problem.

---

## ğŸ‘¥ Team & Hackathon

**Kharagpur Data Science Hackathon 2026**
Organized in collaboration with **Pathway**

---

## ğŸ“„ License

MIT License
